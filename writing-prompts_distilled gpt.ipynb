{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1094951,"sourceType":"datasetVersion","datasetId":611893}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing Libraies\n","metadata":{}},{"cell_type":"code","source":"# Importing the Dataset class from the datasets library\nfrom datasets import Dataset\n\n# Importing the DataCollatorWithPadding class from the transformers library\nfrom transformers import DataCollatorWithPadding\n\n# Importing the Trainer and TrainingArguments classes, GPT2LMHeadModel and GPT2Tokenizer from the transformers library\nfrom transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer\n\n# Importing the PorterStemmer class from the nltk.stem module\nfrom nltk.stem import PorterStemmer\n\n# Importing the string module\nimport string\n\n# Importing the torch library for tensor computations\nimport torch\n\n# Importing the pandas library for data manipulation\nimport pandas as pd\n\n# Importing the SnowballStemmer class from the nltk.stem module\nfrom nltk.stem import SnowballStemmer\n\n# Importing the spacy library for advanced NLP tasks\nimport spacy\n\n# Importing the train_test_split function from the sklearn.model_selection module\nfrom sklearn.model_selection import train_test_split\n\n# Importing the re module for regular expression operations\nimport re\n\n\nimport spacy\n\n\nimport gc\n\n# Importing the warnings module to handle warnings\nimport warnings\n\n# Ignoring any warnings that might be generated when running the code\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:53:59.269875Z","iopub.execute_input":"2024-03-08T14:53:59.270575Z","iopub.status.idle":"2024-03-08T14:54:09.667341Z","shell.execute_reply.started":"2024-03-08T14:53:59.270541Z","shell.execute_reply":"2024-03-08T14:54:09.666370Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-08 14:54:04.371814: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-08 14:54:04.371896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-08 14:54:04.373531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Combining Data In one DF","metadata":{}},{"cell_type":"code","source":"\ndef load_and_preprocess_data(source_file, target_file):\n    # Load the data\n    with open(source_file, 'r') as f:\n        source = f.read().splitlines()\n\n    with open(target_file, 'r') as f:\n        target = f.read().splitlines()\n\n    # Combine the data into one DataFrame\n    df = pd.DataFrame({\n        'source': source,\n        'target': target\n    })\n\n    # Extract tags and create a new column for them\n    df['tag'] = df['source'].apply(lambda x: re.findall(r'\\[(.*?)\\]', x))\n\n    # Remove the tags from the 'source' column\n    df['source'] = df['source'].apply(lambda x: re.sub(r'\\[(.*?)\\]', '', x))\n\n    # Remove any rows with missing values\n    df = df.dropna()\n    \n    return df\n\n\n# Load and preprocess the data\ndf=load_and_preprocess_data('/kaggle/input/writing-prompts/writingPrompts/valid.wp_source','/kaggle/input/writing-prompts/writingPrompts/valid.wp_target')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:09.669340Z","iopub.execute_input":"2024-03-08T14:54:09.670087Z","iopub.status.idle":"2024-03-08T14:54:10.563955Z","shell.execute_reply.started":"2024-03-08T14:54:09.670054Z","shell.execute_reply":"2024-03-08T14:54:10.562744Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:10.565528Z","iopub.execute_input":"2024-03-08T14:54:10.565993Z","iopub.status.idle":"2024-03-08T14:54:10.590288Z","shell.execute_reply.started":"2024-03-08T14:54:10.565950Z","shell.execute_reply":"2024-03-08T14:54:10.589148Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                  source  \\\n0       Every person in the world undergoes a `` good...   \n1       Space mining is on the rise . The Space tanke...   \n2       `` I wo n't have time to explain all of this ...   \n3       Write about a song . Each sentence must start...   \n4       You live in Skyrim . It is your job to keep l...   \n...                                                  ...   \n15615   You are a teenager with the ability to measur...   \n15616   As your dying wish , you ask that your body i...   \n15617   A young child stumbles upon a serial killer d...   \n15618   Write from the perspective of a dog who think...   \n15619   When you die , you do n't go to the afterlife...   \n\n                                                  target     tag  \n0      Clancy Marguerian , 154 , private first class ...  [ WP ]  \n1      „… and the little duckling will never be able ...  [ WP ]  \n2      I wo n't have the time to explain all of this ...  [ WP ]  \n3      * '' [ Sally ] ( https : //www.youtube.com/wat...  [ CW ]  \n4      Light is a marvelous thing . It alone can turn...  [ EU ]  \n...                                                  ...     ...  \n15615  I decided to go with a 1-15 scale instead of 1...  [ WP ]  \n15616  The shock hit me hard as my lungs filled with ...  [ WP ]  \n15617  `` Your mommy and daddy did n't raise you righ...  [ WP ]  \n15618  She wants me to get into the car . It 's just ...  [ WP ]  \n15619  Thomas loves science fiction , and is pleased ...  [ WP ]  \n\n[15620 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Every person in the world undergoes a `` good...</td>\n      <td>Clancy Marguerian , 154 , private first class ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Space mining is on the rise . The Space tanke...</td>\n      <td>„… and the little duckling will never be able ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>`` I wo n't have time to explain all of this ...</td>\n      <td>I wo n't have the time to explain all of this ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Write about a song . Each sentence must start...</td>\n      <td>* '' [ Sally ] ( https : //www.youtube.com/wat...</td>\n      <td>[ CW ]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You live in Skyrim . It is your job to keep l...</td>\n      <td>Light is a marvelous thing . It alone can turn...</td>\n      <td>[ EU ]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15615</th>\n      <td>You are a teenager with the ability to measur...</td>\n      <td>I decided to go with a 1-15 scale instead of 1...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15616</th>\n      <td>As your dying wish , you ask that your body i...</td>\n      <td>The shock hit me hard as my lungs filled with ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15617</th>\n      <td>A young child stumbles upon a serial killer d...</td>\n      <td>`` Your mommy and daddy did n't raise you righ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15618</th>\n      <td>Write from the perspective of a dog who think...</td>\n      <td>She wants me to get into the car . It 's just ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15619</th>\n      <td>When you die , you do n't go to the afterlife...</td>\n      <td>Thomas loves science fiction , and is pleased ...</td>\n      <td>[ WP ]</td>\n    </tr>\n  </tbody>\n</table>\n<p>15620 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Text Normalization: This includes converting all text to lower case, which can help ensure that your algorithm does not treat the same words in different cases as different words.","metadata":{}},{"cell_type":"code","source":"df['source'] = df['source'].str.lower()\ndf['target'] = df['target'].str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:10.592861Z","iopub.execute_input":"2024-03-08T14:54:10.593254Z","iopub.status.idle":"2024-03-08T14:54:10.821359Z","shell.execute_reply.started":"2024-03-08T14:54:10.593222Z","shell.execute_reply":"2024-03-08T14:54:10.820071Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df['target'] = df['target'].str.replace('„', '')\ndf['target'] = df['target'].str.replace('”', '')\ndf['target'] = df['target'].str.replace('< newlin >', ' ')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:10.823014Z","iopub.execute_input":"2024-03-08T14:54:10.823354Z","iopub.status.idle":"2024-03-08T14:54:10.944495Z","shell.execute_reply.started":"2024-03-08T14:54:10.823326Z","shell.execute_reply":"2024-03-08T14:54:10.943538Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Removing Punctuation: Punctuation can provide less value when training language models, and removing it can reduce the size of the vocabulary your model needs to learn.","metadata":{}},{"cell_type":"code","source":"df['source'] = df['source'].str.translate(str.maketrans('', '', string.punctuation))\ndf['target'] = df['target'].str.translate(str.maketrans('', '', string.punctuation))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:10.946108Z","iopub.execute_input":"2024-03-08T14:54:10.946427Z","iopub.status.idle":"2024-03-08T14:54:12.322889Z","shell.execute_reply.started":"2024-03-08T14:54:10.946400Z","shell.execute_reply":"2024-03-08T14:54:12.322026Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:12.324459Z","iopub.execute_input":"2024-03-08T14:54:12.325109Z","iopub.status.idle":"2024-03-08T14:54:12.342590Z","shell.execute_reply.started":"2024-03-08T14:54:12.325074Z","shell.execute_reply":"2024-03-08T14:54:12.341608Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                  source  \\\n0       every person in the world undergoes a  goodne...   \n1       space mining is on the rise  the space tanker...   \n2        i wo nt have time to explain all of this to ...   \n3       write about a song  each sentence must start ...   \n4       you live in skyrim  it is your job to keep li...   \n...                                                  ...   \n15615   you are a teenager with the ability to measur...   \n15616   as your dying wish  you ask that your body is...   \n15617   a young child stumbles upon a serial killer d...   \n15618   write from the perspective of a dog who think...   \n15619   when you die  you do nt go to the afterlife o...   \n\n                                                  target     tag  \n0      clancy marguerian  154  private first class of...  [ WP ]  \n1      … and the little duckling will never be able t...  [ WP ]  \n2      i wo nt have the time to explain all of this t...  [ WP ]  \n3         sally   https  wwwyoutubecomwatch  v6qyvil0...  [ CW ]  \n4      light is a marvelous thing  it alone can turn ...  [ EU ]  \n...                                                  ...     ...  \n15615  i decided to go with a 115 scale instead of 11...  [ WP ]  \n15616  the shock hit me hard as my lungs filled with ...  [ WP ]  \n15617   your mommy and daddy did nt raise you right  ...  [ WP ]  \n15618  she wants me to get into the car  it s just so...  [ WP ]  \n15619  thomas loves science fiction  and is pleased t...  [ WP ]  \n\n[15620 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>every person in the world undergoes a  goodne...</td>\n      <td>clancy marguerian  154  private first class of...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>space mining is on the rise  the space tanker...</td>\n      <td>… and the little duckling will never be able t...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i wo nt have time to explain all of this to ...</td>\n      <td>i wo nt have the time to explain all of this t...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>write about a song  each sentence must start ...</td>\n      <td>sally   https  wwwyoutubecomwatch  v6qyvil0...</td>\n      <td>[ CW ]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>you live in skyrim  it is your job to keep li...</td>\n      <td>light is a marvelous thing  it alone can turn ...</td>\n      <td>[ EU ]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15615</th>\n      <td>you are a teenager with the ability to measur...</td>\n      <td>i decided to go with a 115 scale instead of 11...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15616</th>\n      <td>as your dying wish  you ask that your body is...</td>\n      <td>the shock hit me hard as my lungs filled with ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15617</th>\n      <td>a young child stumbles upon a serial killer d...</td>\n      <td>your mommy and daddy did nt raise you right  ...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15618</th>\n      <td>write from the perspective of a dog who think...</td>\n      <td>she wants me to get into the car  it s just so...</td>\n      <td>[ WP ]</td>\n    </tr>\n    <tr>\n      <th>15619</th>\n      <td>when you die  you do nt go to the afterlife o...</td>\n      <td>thomas loves science fiction  and is pleased t...</td>\n      <td>[ WP ]</td>\n    </tr>\n  </tbody>\n</table>\n<p>15620 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['target'] = df['target'].str.replace('newline', '')\ndf['source'] = df['source'].str.replace('newline', '')","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:12.343812Z","iopub.execute_input":"2024-03-08T14:54:12.344206Z","iopub.status.idle":"2024-03-08T14:54:12.539555Z","shell.execute_reply.started":"2024-03-08T14:54:12.344177Z","shell.execute_reply":"2024-03-08T14:54:12.538691Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Lemmatization: These techniques are used to reduce words to their root form. This can help your model generalize better to variations of words.","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\n\n# Apply lemmatization to each word in the 'source' and 'target' columns of your DataFrame\ndf['source'] = df['source'].apply(lambda x: ' '.join([token.lemma_ for token in nlp(x)]))\ndf['target'] = df['target'].apply(lambda x: ' '.join([token.lemma_ for token in nlp(x)]))\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:12.541983Z","iopub.execute_input":"2024-03-08T14:54:12.542299Z","iopub.status.idle":"2024-03-08T14:54:12.552584Z","shell.execute_reply.started":"2024-03-08T14:54:12.542271Z","shell.execute_reply":"2024-03-08T14:54:12.551319Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Clear GPU memory\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:12.554122Z","iopub.execute_input":"2024-03-08T14:54:12.554491Z","iopub.status.idle":"2024-03-08T14:54:12.559652Z","shell.execute_reply.started":"2024-03-08T14:54:12.554463Z","shell.execute_reply":"2024-03-08T14:54:12.558661Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Force garbage collection\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:13.400246Z","iopub.execute_input":"2024-03-08T14:54:13.401356Z","iopub.status.idle":"2024-03-08T14:54:13.768159Z","shell.execute_reply.started":"2024-03-08T14:54:13.401310Z","shell.execute_reply":"2024-03-08T14:54:13.766906Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"287"},"metadata":{}}]},{"cell_type":"code","source":"def load_dataset(train_df, valid_df, tokenizer):\n    train_dataset = Dataset.from_pandas(train_df)\n    valid_dataset = Dataset.from_pandas(valid_df)\n\n    def tokenize_function(examples):\n        tokenized_inputs = tokenizer(examples[\"source\"], truncation=True, padding=\"max_length\")\n        tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()\n        return tokenized_inputs\n\n    train_dataset = train_dataset.map(tokenize_function, batched=True)\n    valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n\n    return train_dataset, valid_dataset\n\ntraining_args = TrainingArguments(\n    output_dir=\"./distilgpt2_story_gen\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\ntokenizer.pad_token = tokenizer.eos_token\n\n# Make sure to define train_df and valid_df before this line\ntrain_dataset, valid_dataset = load_dataset(train_df, valid_df, tokenizer)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nmodel = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T14:54:14.645916Z","iopub.execute_input":"2024-03-08T14:54:14.646980Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2342aea9215e46bba3b6ac927a133db4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5316e69aca7c436e813988e95b62ffa6"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240308_145514-tducpgjl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/one_man_army007/huggingface/runs/tducpgjl' target=\"_blank\">feasible-thunder-3</a></strong> to <a href='https://wandb.ai/one_man_army007/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/one_man_army007/huggingface' target=\"_blank\">https://wandb.ai/one_man_army007/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/one_man_army007/huggingface/runs/tducpgjl' target=\"_blank\">https://wandb.ai/one_man_army007/huggingface/runs/tducpgjl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='493' max='18744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  493/18744 02:31 < 1:33:46, 3.24 it/s, Epoch 0.08/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the trained model\ntrainer.save_model(\"./creative_writing_distilgpt2_story_gen\")\n\n# Save the tokenizer\ntokenizer.save_pretrained(\"./creative_writing_distilgpt2_story_gen\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}